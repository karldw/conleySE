{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import feather\n",
    "from ball_tree import BallTree  # TODO: force python to only look locally for import\n",
    "from faster_sandwich_filling import multiply_XeeX, CutoffError, GeographyError, get_kernel_fn\n",
    "from numpy.testing import assert_allclose\n",
    "from patsy import dmatrices, dmatrix\n",
    "from core import parse_lat_long, check_parameters\n",
    "from scipy.sparse import csr_matrix, coo_matrix, diags\n",
    "from typedefs import ITYPE, DTYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext Cython\n",
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conley_cross_section(formula_like, data, lat_long, cutoff, kernel = 'uniform'):\n",
    "    \"\"\"Calculate Conley standard errors for a cross section.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    formula_like : string or other Patsy formula\n",
    "        e.g. \"my_y_variable = my_X_var1 + my_X_var2\"\n",
    "        See http://patsy.readthedocs.io/en/latest/formulas.html#formulas for\n",
    "        details on Patsy formulas.\n",
    "    data : array-like\n",
    "        Must contain all the variables referenced in the formula.\n",
    "    lat_long : array_like, or tuple of names of columns in data\n",
    "        An N-by-2 array of latitudes (in the first column) and longitudes (in\n",
    "        the second column). Both latitude and longitude should be measured\n",
    "        in degrees. Valid longitudes are [-90, 90].  Valid latitudes are\n",
    "        (-180, 180]. The number of rows should be the same as the rows in data.\n",
    "    cutoff : number\n",
    "        The maximum distance over which covariance is possible.\n",
    "        cutoff must be a positive number in the range (0, 20015).\n",
    "    kernel : string\n",
    "        The kernel function to weight the distances by. Valid options are:\n",
    "        'bartlett', 'triangle', 'epanechnikov', 'quartic', 'biweight' and\n",
    "        'triweight'. (Bartlett is the same as triangle. Quartic is the same as\n",
    "        biweight.)\n",
    "    \"\"\"\n",
    "    y, X = dmatrices(formula_like, data, eval_env = 1, NA_action = 'raise')\n",
    "    # TODO: handle cases where people provide weird formulas?\n",
    "\n",
    "    lat_long = parse_lat_long(lat_long, data)\n",
    "    # Raise an exception if the data look funky\n",
    "    nobs = check_parameters(y, X, lat_long, cutoff)\n",
    "\n",
    "    # I have no idea if this leaf_size is reasonable.  If running out of memory,\n",
    "    # divide N by a larger number.\n",
    "    # 40 is the default.\n",
    "    leaf_size = max(40, nobs // 1000)\n",
    "    # TODO: consider a more sophisticated way of calculating residuals (e.g. one that\n",
    "    # allows for fancy fixed effects)\n",
    "    betahat, _, rank, _ = np.linalg.lstsq(X, y)\n",
    "    if rank != X.shape[1]:\n",
    "        raise np.linalg.LinAlgError('X matrix is not full rank!')\n",
    "    del rank\n",
    "    residuals = (y - X @ betahat)[0]\n",
    "    balltree = BallTree(lat_long, metric = 'greatcircle', leaf_size = leaf_size)\n",
    "    if kernel == 'uniform':\n",
    "        neighbors = balltree.query_radius(lat_long, r = cutoff)\n",
    "        filling = multiply_XeeX(neighbors, residuals, X, kernel)\n",
    "    else:\n",
    "        neighbors, neighbor_distances = balltree.query_radius(\n",
    "            lat_long, r = cutoff, return_distance = True)\n",
    "        filling = multiply_XeeX(neighbors, residuals, X, kernel,\n",
    "                                distances = neighbor_distances, cutoff = cutoff)\n",
    "        del neighbor_distances\n",
    "    del balltree, neighbors, y, residuals\n",
    "\n",
    "    bread = np.linalg.inv(X.T @ X)\n",
    "    sandwich = nobs * (bread.T @ filling @ bread)\n",
    "    se = np.sqrt(np.diag(sandwich)).reshape(-1, 1)\n",
    "    return se\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_quakes():\n",
    "    quakes = feather.read_dataframe('tests/datasets/quakes.feather')\n",
    "    quakes_lat = quakes['lat'].reshape(-1, 1)\n",
    "    # Subtract 180 because they've done 0 to 360.  See:\n",
    "    # https://stackoverflow.com/questions/19879746/why-are-datasetquakes-longtitude-values-above-180\n",
    "    quakes_long = quakes['long'].reshape(-1, 1) - 180\n",
    "    quakes_lat_long = np.hstack((quakes_lat, quakes_long))\n",
    "    cutoff = 100\n",
    "\n",
    "    # correct_results = conley_unfancy(quakes_y, quakes_X, quakes_lat_long, cutoff)\n",
    "    correct_results = np.array((108.723235, 19.187791)).reshape(-1, 1)  # faster testing\n",
    "    fast_results = conley_cross_section(\"depth ~ mag\", quakes,\n",
    "                                        quakes_lat_long, cutoff)\n",
    "    assert_allclose(correct_results, fast_results)\n",
    "# test_quakes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quakes = feather.read_dataframe('tests/datasets/quakes.feather')\n",
    "quakes_lat = quakes['lat'].reshape(-1, 1)\n",
    "quakes_long = quakes['long'].reshape(-1, 1) - 180\n",
    "quakes_lat_long = np.hstack((quakes_lat, quakes_long))\n",
    "cutoff = 100\n",
    "\n",
    "balltree = BallTree(quakes_lat_long, metric = 'greatcircle')\n",
    "neighbors, distances = balltree.query_radius(quakes_lat_long, r = cutoff, return_distance = True)\n",
    "\n",
    "    \n",
    "y, X = dmatrices(data=quakes, formula_like='depth ~ mag')\n",
    "betahat, _, rank, _ = np.linalg.lstsq(X, y)\n",
    "if rank != X.shape[1]:\n",
    "    raise np.linalg.LinAlgError('X matrix is not full rank!')\n",
    "del rank\n",
    "residuals = (y - X @ betahat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conley_unfancy(y, X, lat_long, cutoff):\n",
    "    N = y.shape[0]\n",
    "    k = X.shape[1]\n",
    "    bread = np.linalg.inv(X.T @ X)  # 'bread' in the sandwich-estimator sense\n",
    "\n",
    "    # Run OLS to get residuals\n",
    "    betahat = bread @ X.T @ y  # '@' is matrix multiplication, equivalent to np.dot\n",
    "    residuals = y - X @ betahat\n",
    "    meat_matrix = np.zeros((k, k))\n",
    "    row_of_ones = np.ones((1, N))\n",
    "    column_of_ones = np.ones((k, 1))\n",
    "    # every_point_is_a_neighbor_of_every_other = True\n",
    "    for i in range(N):\n",
    "        dist = great_circle_one_to_many(lat_long, lat_long[i])\n",
    "\n",
    "        window = dist <= cutoff\n",
    "        # if not all(window):\n",
    "        #     every_point_is_a_neighbor_of_every_other = False\n",
    "        X_i = X[i, ].reshape(-1, 1)\n",
    "        residuals_i = residuals[i, ].reshape(-1, 1)\n",
    "\n",
    "        #         k x 1       1 x n        1 x 1\n",
    "        XeeXh = (((X_i @ row_of_ones * residuals_i) *\n",
    "                  (column_of_ones @ (residuals.T * window.T))) @ X)\n",
    "        #                 k x 1                1 x n            n x k\n",
    "        meat_matrix += XeeXh\n",
    "    meat_matrix = meat_matrix / N\n",
    "\n",
    "    sandwich = N * (bread.T @ meat_matrix @ bread)\n",
    "    se = np.sqrt(np.diag(sandwich)).reshape(-1, 1)\n",
    "    return se\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# def neighbors_to_sparse_nonuniform(neighbors, distances, kernel, cutoff):\n",
    "#     nrow = neighbors.shape[0]\n",
    "#     if distances is None:\n",
    "#         raise ValueError('You must provide distances if using a non-uniform kernel')\n",
    "#     if cutoff is None:\n",
    "#         raise ValueError('You must provide a cutoff if using a non-uniform kernel')\n",
    "#     if distances.shape[0] != nrow:\n",
    "#         raise ValueError('neighbors and distances have different numbers of rows')\n",
    "        \n",
    "#     neighbors_lil = lil_matrix((nrow, nrow), dtype=np.float_)\n",
    "#     kernel_fn = get_kernel_fn(kernel)\n",
    "#     for i, neighbor_list in enumerate(neighbors):\n",
    "#         assert neighbor_list.shape == distances[i].shape\n",
    "#         # fun fact: you have to apply the kernel function here; you can't do a sparse matrix \n",
    "#         # of distances, since some distances (e.g. distance with self) are zero.\n",
    "#         neighbors_lil[i, neighbor_list] = kernel_fn(distances[i], cutoff)\n",
    "#     return neighbors_lil.tocsr()\n",
    "\n",
    "\n",
    "# def neighbors_to_sparse_uniform(neighbors):\n",
    "#     nrow = neighbors.shape[0]\n",
    "#     neighbors_lil = lil_matrix((nrow, nrow), dtype=np.float_)\n",
    "#     for i, neighbor_list in enumerate(neighbors):\n",
    "#         neighbors_lil[i, neighbor_list] = 1\n",
    "#     return neighbors_lil.tocsr()\n",
    "\n",
    "\n",
    "# def neighbors_to_sparse(neighbors, kernel = 'uniform', distances = None, cutoff = None):\n",
    "#     if kernel == 'uniform':\n",
    "#         if cutoff is not None or distances is not None:\n",
    "#             raise ValueError(\"this combination of parameters should never be necessary; it's a coding mistake\")\n",
    "#         return neighbors_to_sparse_uniform(neighbors)\n",
    "#     else:\n",
    "#         return neighbors_to_sparse_nonuniform(neighbors, distances, kernel, cutoff)\n",
    "\n",
    "# neighbors_sp = neighbors_to_sparse(neighbors)\n",
    "# neighbors_sp[1,100]\n",
    "\n",
    "\n",
    "# nrow = residuals.shape[0]\n",
    "# # not smart enough to convert an (N, 1) array to a (N,) array, so manually reshape\n",
    "# resid_diag_matrix = diags(residuals.reshape(-1), offsets=0, shape = (nrow, nrow))\n",
    "# resid_x_neighbors = neighbors_sp * resid_diag_matrix\n",
    "\n",
    "# for i in range(residuals.shape[0]):\n",
    "#     resid_x_neighbors[i, :] *= residuals\n",
    "\n",
    "\n",
    "#type(neighbors_sp)\n",
    "#print(resid_x_neighbors, neighbors_sp)\n",
    "# at_mult = \n",
    "# star_mult = X.T * resid_x_neighbors * X\n",
    "\n",
    "# print(at_mult.shape)\n",
    "# at_mult, star_mult)\n",
    "# residuals.reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# %%cython\n",
    "# import numpy as np\n",
    "# cimport numpy as np\n",
    "# from typedefs cimport DTYPE_t, ITYPE_t\n",
    "# from typedefs import DTYPE, ITYPE\n",
    "# import cython\n",
    "# from scipy.sparse import coo_matrix, csr_matrix\n",
    "# np.import_array()\n",
    "\n",
    "\n",
    "# def neighbors_to_sparse_cython(\n",
    "#         object[:] neighbors not None, \n",
    "#         str kernel not None, \n",
    "#         object[:] distances = None, \n",
    "#         DTYPE_t cutoff = None):\n",
    "\n",
    "#     if kernel == 'uniform':\n",
    "#         if cutoff is not None or distances is not None:\n",
    "#             err_msg = \"this combination of parameters should never be necessary; it's a coding mistake\"\n",
    "#             raise ValueError(err_msg)\n",
    "#         neighbors_sparse = neighbors_to_sparse_uniform_cython(neighbors)\n",
    "#     else:\n",
    "#         if cutoff is None or distances is None:\n",
    "#             err_msg = \"this combination of parameters should never be necessary; it's a coding mistake\"\n",
    "#             raise ValueError(err_msg)\n",
    "#         neighbors_sparse = neighbors_to_sparse_nonuniform_cython(neighbors, kernel, distances, cutoff)\n",
    "#     return neighbors_sparse\n",
    "\n",
    "\n",
    "# @cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "# @cython.wraparound(False)  # turn off negative indexing\n",
    "# cdef neighbors_to_sparse_uniform_cython(object[:] neighbors):\n",
    "#     cdef ITYPE_t i_neighbor\n",
    "#     cdef ITYPE_t nrow = len(neighbors)\n",
    "#     # collect neighbor counts for nnz and the inner loop below\n",
    "#     cdef ITYPE_t[:] neighbor_counts = np.empty(nrow, dtype=ITYPE)\n",
    "    \n",
    "#     for i_neighbor in range(nrow):\n",
    "#         neighbor_counts[i_neighbor] = len(neighbors[i_neighbor])\n",
    "#     cdef ITYPE_t nnz = np.sum(neighbor_counts)  # number of non-zeros\n",
    "    \n",
    "#     cdef ITYPE_t[:] rows = np.empty(nnz, dtype=ITYPE)\n",
    "#     cdef ITYPE_t[:] cols = np.empty(nnz, dtype=ITYPE)\n",
    "#     # for values, use dtype (i.e., float64) because even though it's \n",
    "#     # always going to be 1, I want the same type for nonuniform\n",
    "#     cdef DTYPE_t[:] values = np.ones(nnz, dtype=DTYPE)  \n",
    "    \n",
    "#     cdef ITYPE_t[:] neighbors_row\n",
    "#     cdef ITYPE_t row_idx, neighbor_id\n",
    "#     cdef ITYPE_t sparse_idx = 0\n",
    "#     cdef ITYPE_t n_neighbors\n",
    "#     for row_idx in range(nrow):\n",
    "#         neighbors_row = neighbors[row_idx]\n",
    "#         # In case anyone wants to run this in parallel, release the GIL\n",
    "#         with nogil:\n",
    "#             for neighbor_id in range(neighbor_counts[row_idx]):\n",
    "#                 rows[sparse_idx] = row_idx\n",
    "#                 cols[sparse_idx] = neighbors_row[neighbor_id]\n",
    "#                 sparse_idx += 1\n",
    "#     # Finally, we construct a regular SciPy sparse matrix:\n",
    "#     return coo_matrix((values, (rows, cols)), shape=(nrow, nrow)).tocsr()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# cdef DTYPE_t bartlett_once(DTYPE_t dist, DTYPE_t cutoff) nogil:\n",
    "#     \"\"\"Weight distances by the Bartlett (triangular) kernel.\n",
    "\n",
    "#     Important: The function _does not_ check weather the distance is outside the\n",
    "#     cutoff.  You should do this elsewhere.\n",
    "\n",
    "#     Input: A memoryview of distances (float64) and a cutoff (float64).\n",
    "#     Output: A memoryview of weights (float64) in the range [0, 1].\n",
    "#     \"\"\"\n",
    "#     cdef DTYPE_t weight = 1 - (dist / cutoff)\n",
    "#     return weight\n",
    "\n",
    "\n",
    "# cdef DTYPE_t epanechnikov_once(DTYPE_t dist, DTYPE_t cutoff) nogil:\n",
    "#     \"\"\"Weight distances by the Epanechnikov kernel.\n",
    "\n",
    "#     Important: The function _does not_ check weather the distance is outside the\n",
    "#     cutoff.  You should do this elsewhere.\n",
    "\n",
    "#     Input: A distance (float64) and a cutoff (float64).\n",
    "#     Output: A weight (float64) in the range [0, 1].\n",
    "#     \"\"\"\n",
    "#     cdef DTYPE_t weight = (0.75 / cutoff) * (1 - (1 / (cutoff**2)) * dist**2)\n",
    "#     return weight\n",
    "\n",
    "\n",
    "# # cdef kernel_dict = {\n",
    "# #     'bartlett': bartlett_once,\n",
    "# #     'Bartlett': bartlett_once,\n",
    "# #     'triangle': bartlett_once,\n",
    "# #     'Epanechnikov': epanechnikov_once,\n",
    "# #     'epanechnikov': epanechnikov_once,\n",
    "# #     }\n",
    "\n",
    "# @cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "# @cython.wraparound(False)  # turn off negative indexing\n",
    "# cpdef neighbors_to_sparse_nonuniform_cython(\n",
    "#         object[:] neighbors, \n",
    "#         str kernel, \n",
    "#         object[:] distances, \n",
    "#         DTYPE_t cutoff):\n",
    "#     assert cutoff is not None\n",
    "#     kernel_fn = get_kernel_fn(kernel)\n",
    "# #     assert callable(kernel_fn)\n",
    "#     cdef ITYPE_t i_neighbor\n",
    "#     cdef ITYPE_t nrow = len(neighbors)\n",
    "#     # collect neighbor counts for nnz and the inner loop below\n",
    "#     cdef ITYPE_t[:] neighbor_counts = np.empty(nrow, dtype=ITYPE)\n",
    "    \n",
    "#     for i_neighbor in range(nrow):\n",
    "#         neighbor_counts[i_neighbor] = len(neighbors[i_neighbor])\n",
    "#     cdef ITYPE_t nnz = np.sum(neighbor_counts)  # number of non-zeros\n",
    "    \n",
    "#     cdef ITYPE_t[:] rows = np.empty(nnz, dtype=ITYPE)\n",
    "#     cdef ITYPE_t[:] cols = np.empty(nnz, dtype=ITYPE)\n",
    "#     # for values, use dtype (i.e., float64) because even though it's \n",
    "#     # always going to be 1, I want the same type for nonuniform\n",
    "#     cdef DTYPE_t[:] values = np.empty(nnz, dtype=DTYPE)  \n",
    "    \n",
    "#     cdef ITYPE_t[:] neighbors_row\n",
    "# #     cdef DTYPE_t[:] distances_row\n",
    "#     cdef DTYPE_t[:] value_row\n",
    "#     cdef ITYPE_t row_idx, neighbor_idx\n",
    "#     cdef ITYPE_t sparse_idx = 0\n",
    "#     cdef ITYPE_t n_neighbors\n",
    "#     for row_idx in range(nrow):\n",
    "#         n_neighbors = neighbor_counts[row_idx]  # count of neighbors in this row\n",
    "#         neighbors_row = neighbors[row_idx]  # neighbor IDs for this row\n",
    "# #         distances_row = distances[row_idx]\n",
    "#         # call vectorized kernel fn and paste values in\n",
    "#         value[sparse_idx: (sparse_idx + n_neighbors + 1)] = kernel_fn(distances[row_idx], cutoff)\n",
    "#         # In case anyone wants to run this in parallel, release the GIL\n",
    "#         with nogil:\n",
    "#             for neighbor_idx in range(n_neighbors):\n",
    "#                 rows[sparse_idx] = row_idx\n",
    "#                 cols[sparse_idx] = neighbors_row[neighbor_idx]\n",
    "# #                 values[sparse_idx] = kernel_fn(distances_row[neighbor_id], cutoff)\n",
    "#                 sparse_idx += 1\n",
    "#     # Finally, we construct a regular SciPy sparse matrix:\n",
    "#     return coo_matrix((values, (rows, cols)), shape=(nrow, nrow)).tocsr()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %timeit neighbors_to_sparse_uniform_cython(neighbors)\n",
    "# %timeit neighbors_to_sparse_nonuniform_cython(neighbors, 'epanechnikov', distances, cutoff)\n",
    "# %timeit neighbors_to_sparse_nonuniform_cython(neighbors, 'bartlett', distances, cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 5.7 ms per loop\n",
      "100 loops, best of 3: 9.96 ms per loop\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def neighbors_to_sparse_uniform_old(neighbors):\n",
    "    nrow = neighbors.shape[0]\n",
    "    neighbors_lil = lil_matrix((nrow, nrow), dtype=np.float_)\n",
    "    for i, neighbor_list in enumerate(neighbors):\n",
    "        neighbors_lil[i, neighbor_list] = 1\n",
    "    return neighbors_lil.tocsr()\n",
    "#%timeit neighbors_to_sparse_uniform(neighbors)\n",
    "\n",
    "\n",
    "def neighbors_to_sparse_uniform(neighbors):\n",
    "    nrow = len(neighbors)\n",
    "    nnz = 0  # number of non-zeros\n",
    "    for i_neighbor in range(nrow):\n",
    "        nnz += len(neighbors[i_neighbor])\n",
    "    rows = np.empty(nnz, dtype=ITYPE)\n",
    "    cols = np.empty(nnz, dtype=ITYPE)\n",
    "    vals = np.ones(nnz,  dtype=DTYPE)  \n",
    "    sparse_idx = 0\n",
    "    for row_idx in range(nrow):\n",
    "        neighbors_row = neighbors[row_idx]\n",
    "        n_neighbors = len(neighbors_row)\n",
    "        end_idx = sparse_idx + n_neighbors\n",
    "        rows[sparse_idx: end_idx] = row_idx\n",
    "        cols[sparse_idx: end_idx] = neighbors_row\n",
    "        sparse_idx += n_neighbors\n",
    "    assert rows.shape[0] == cols.shape[0] == nnz\n",
    "\n",
    "    # Finally, we construct a regular SciPy sparse matrix:\n",
    "    return coo_matrix((vals, (rows, cols)), shape=(nrow, nrow)).tocsr()\n",
    "\n",
    "\n",
    "def neighbors_to_sparse_nonuniform(neighbors, kernel, distances, cutoff):\n",
    "    kernel_fn = get_kernel_fn(kernel)\n",
    "    nrow = len(neighbors)\n",
    "    \n",
    "    nnz = 0  # number of non-zeros\n",
    "    for i_neighbor in range(nrow):\n",
    "        nnz += len(neighbors[i_neighbor])\n",
    "    rows = np.empty(nnz, dtype=ITYPE)\n",
    "    cols = np.empty(nnz, dtype=ITYPE)\n",
    "    vals = np.empty(nnz, dtype=DTYPE)  \n",
    "    sparse_idx = 0\n",
    "    for row_idx in range(nrow):\n",
    "        neighbors_row = neighbors[row_idx]\n",
    "        n_neighbors = len(neighbors_row)\n",
    "        end_idx = sparse_idx + n_neighbors\n",
    "        rows[sparse_idx: end_idx] = row_idx\n",
    "        cols[sparse_idx: end_idx] = neighbors_row\n",
    "        vals[sparse_idx: end_idx] = kernel_fn(distances[row_idx], cutoff)\n",
    "        sparse_idx += n_neighbors\n",
    "    assert rows.shape[0] == cols.shape[0] == vals.shape[0] == nnz\n",
    "\n",
    "    # Finally, we construct a regular SciPy sparse matrix:\n",
    "    return coo_matrix((vals, (rows, cols)), shape=(nrow, nrow)).tocsr()\n",
    "\n",
    "\n",
    "def neighbors_to_sparse(neighbors, kernel = 'uniform', distances = None, cutoff = None):\n",
    "    if kernel == 'uniform':\n",
    "        if cutoff is not None or distances is not None:\n",
    "            err_msg = \"this combination of parameters should never be necessary; it's a coding mistake\"\n",
    "            raise ValueError(err_msg)\n",
    "        neighbors_sparse = neighbors_to_sparse_uniform(neighbors)\n",
    "    else:\n",
    "        if cutoff is None or distances is None:\n",
    "            err_msg = \"this combination of parameters should never be necessary; it's a coding mistake\"\n",
    "            raise ValueError(err_msg)\n",
    "        if len(neighbors) != len(distances):\n",
    "            err_msg = \"Number of neighbors and distances don't match.\"\n",
    "            raise ValueError(err_msg)\n",
    "        neighbors_sparse = neighbors_to_sparse_nonuniform(neighbors, kernel, distances, cutoff)\n",
    "    return neighbors_sparse\n",
    "\n",
    "%timeit neighbors_to_sparse_uniform(neighbors)\n",
    "%timeit neighbors_to_sparse_nonuniform(neighbors, 'bartlett', distances, cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def test_neighbors_to_sparse(neighbors, kernel, distances, cutoff):\n",
    "    from scipy.sparse import find\n",
    "    neighbors_sparse_nodistance = neighbors_to_sparse(neighbors)\n",
    "    neighbors_sparse_withdistance = neighbors_to_sparse(neighbors, kernel, distances, cutoff)\n",
    "    kernel_fn = get_kernel_fn(kernel)\n",
    "    for i in range(neighbors.shape[0]):\n",
    "        neighbors_row_argsort = np.argsort(neighbors[i])  # get the indexes that will sort the row\n",
    "        neighbors_row_sorted = neighbors[i][neighbors_row_argsort]\n",
    "        \n",
    "        distance_row_sorted = kernel_fn(distances[i][neighbors_row_argsort], cutoff)\n",
    "        \n",
    "        # test that the neighbor indexes are the same\n",
    "        np.testing.assert_equal(find(neighbors_sparse_nodistance.getrow(i))[1], neighbors_row_sorted)\n",
    "        np.testing.assert_equal(find(neighbors_sparse_withdistance.getrow(i))[1], neighbors_row_sorted)\n",
    "        # test that the distance weight values are the same\n",
    "        np.testing.assert_equal(find(neighbors_sparse_withdistance.getrow(i))[2], distance_row_sorted)\n",
    "# just picked one kernel for testing\n",
    "test_neighbors_to_sparse(neighbors, 'epanechnikov', distances, cutoff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def test_mult(X, residuals, neighbors, kernel, distances = None, cutoff = None):\n",
    "    N = X.shape[0]\n",
    "    k = X.shape[1]\n",
    "    \n",
    "    \n",
    "    meat_matrix = np.zeros((k, k))\n",
    "    row_of_ones = np.ones((1, N))\n",
    "    column_of_ones = np.ones((k, 1))\n",
    "    # neighbors_to_sparse will get the uniform or the kernel-ized version, as necessary\n",
    "    neighbors_sp = neighbors_to_sparse(neighbors, kernel, distances, cutoff )\n",
    "    \n",
    "    neighbors_dense = neighbors_sp.toarray()\n",
    "    for i in range(N):\n",
    "        window = neighbors_dense[i, :]\n",
    "        X_i = X[i, ].reshape(-1, 1)\n",
    "        residuals_i = residuals[i, ].reshape(-1, 1)\n",
    "        \n",
    "        #         k x 1       1 x n        1 x 1\n",
    "        XeeXh = (((X_i @ row_of_ones * residuals_i) *\n",
    "                  (column_of_ones @ (residuals.T * window.T))) @ X)\n",
    "        #                 k x 1                1 x n            n x k\n",
    "        meat_matrix += XeeXh\n",
    "    correct = meat_matrix / N\n",
    "    \n",
    "    # I want element-wise multiplication of the residuals vector by the neighbors weights matrix.\n",
    "    # Sparse matrices don't have element-wise multiplication, but it's equivalent to cast \n",
    "    # the residuals as a sparse diagonal matrix, then do matrix multiplication.\n",
    "    # The diags function isn't smart enough to convert an (N, 1) array to a (N,) array, so manually reshape.\n",
    "    # Then, unlike numpy arrays, with sparse matrices, '*' means matrix multiplication, NOT element-wise.\n",
    "    resid_diag_matrix = diags(residuals.reshape(-1), offsets = 0, shape = (N, N))    \n",
    "    resid_x_neighbors = resid_diag_matrix * neighbors_sp * resid_diag_matrix\n",
    "    \n",
    "    proposed = (X.T @ resid_x_neighbors @ X) / N\n",
    "    np.testing.assert_allclose(correct, proposed)\n",
    "    \n",
    "    bread = np.linalg.inv(X.T @ X)\n",
    "    correct_sandwich = N * (bread.T @ correct @ bread)\n",
    "    correct_se = np.sqrt(np.diag(correct_sandwich)).reshape(-1, 1)\n",
    "    proposed_sandwich = N * (bread.T @ proposed @ bread)\n",
    "    proposed_se = np.sqrt(np.diag(proposed_sandwich)).reshape(-1, 1)\n",
    "    np.testing.assert_allclose(correct_se, proposed_se)\n",
    "    \n",
    "    \n",
    "test_mult(X, residuals, neighbors, 'uniform')\n",
    "test_mult(X, residuals, neighbors, 'epanechnikov', distances, cutoff)\n",
    "test_mult(X, residuals, neighbors, 'bartlett', distances, cutoff)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
