{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import feather\n",
    "from ball_tree import BallTree  # TODO: force python to only look locally for import\n",
    "from faster_sandwich_filling import multiply_XeeX, CutoffError, GeographyError, get_kernel_fn\n",
    "from numpy.testing import assert_allclose\n",
    "from patsy import dmatrices, dmatrix\n",
    "from core import parse_lat_long, check_parameters\n",
    "from scipy.sparse import csr_matrix, lil_matrix, diags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conley_cross_section(formula_like, data, lat_long, cutoff, kernel = 'uniform'):\n",
    "    \"\"\"Calculate Conley standard errors for a cross section.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    formula_like : string or other Patsy formula\n",
    "        e.g. \"my_y_variable = my_X_var1 + my_X_var2\"\n",
    "        See http://patsy.readthedocs.io/en/latest/formulas.html#formulas for\n",
    "        details on Patsy formulas.\n",
    "    data : array-like\n",
    "        Must contain all the variables referenced in the formula.\n",
    "    lat_long : array_like, or tuple of names of columns in data\n",
    "        An N-by-2 array of latitudes (in the first column) and longitudes (in\n",
    "        the second column). Both latitude and longitude should be measured\n",
    "        in degrees. Valid longitudes are [-90, 90].  Valid latitudes are\n",
    "        (-180, 180]. The number of rows should be the same as the rows in data.\n",
    "    cutoff : number\n",
    "        The maximum distance over which covariance is possible.\n",
    "        cutoff must be a positive number in the range (0, 20015).\n",
    "    kernel : string\n",
    "        The kernel function to weight the distances by. Valid options are:\n",
    "        'bartlett', 'triangle', 'epanechnikov', 'quartic', 'biweight' and\n",
    "        'triweight'. (Bartlett is the same as triangle. Quartic is the same as\n",
    "        biweight.)\n",
    "    \"\"\"\n",
    "    y, X = dmatrices(formula_like, data, eval_env = 1, NA_action = 'raise')\n",
    "    # TODO: handle cases where people provide weird formulas?\n",
    "\n",
    "    lat_long = parse_lat_long(lat_long, data)\n",
    "    # Raise an exception if the data look funky\n",
    "    nobs = check_parameters(y, X, lat_long, cutoff)\n",
    "\n",
    "    # I have no idea if this leaf_size is reasonable.  If running out of memory,\n",
    "    # divide N by a larger number.\n",
    "    # 40 is the default.\n",
    "    leaf_size = max(40, nobs // 1000)\n",
    "    # TODO: consider a more sophisticated way of calculating residuals (e.g. one that\n",
    "    # allows for fancy fixed effects)\n",
    "    betahat, _, rank, _ = np.linalg.lstsq(X, y)\n",
    "    if rank != X.shape[1]:\n",
    "        raise np.linalg.LinAlgError('X matrix is not full rank!')\n",
    "    del rank\n",
    "    residuals = (y - X @ betahat)[0]\n",
    "    balltree = BallTree(lat_long, metric = 'greatcircle', leaf_size = leaf_size)\n",
    "    if kernel == 'uniform':\n",
    "        neighbors = balltree.query_radius(lat_long, r = cutoff)\n",
    "        filling = multiply_XeeX(neighbors, residuals, X, kernel)\n",
    "    else:\n",
    "        neighbors, neighbor_distances = balltree.query_radius(\n",
    "            lat_long, r = cutoff, return_distance = True)\n",
    "        filling = multiply_XeeX(neighbors, residuals, X, kernel,\n",
    "                                distances = neighbor_distances, cutoff = cutoff)\n",
    "        del neighbor_distances\n",
    "    del balltree, neighbors, y, residuals\n",
    "\n",
    "    bread = np.linalg.inv(X.T @ X)\n",
    "    sandwich = nobs * (bread.T @ filling @ bread)\n",
    "    se = np.sqrt(np.diag(sandwich)).reshape(-1, 1)\n",
    "    return se\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_quakes():\n",
    "    quakes = feather.read_dataframe('tests/datasets/quakes.feather')\n",
    "    quakes_lat = quakes['lat'].reshape(-1, 1)\n",
    "    # Subtract 180 because they've done 0 to 360.  See:\n",
    "    # https://stackoverflow.com/questions/19879746/why-are-datasetquakes-longtitude-values-above-180\n",
    "    quakes_long = quakes['long'].reshape(-1, 1) - 180\n",
    "    quakes_lat_long = np.hstack((quakes_lat, quakes_long))\n",
    "    cutoff = 100\n",
    "\n",
    "    # correct_results = conley_unfancy(quakes_y, quakes_X, quakes_lat_long, cutoff)\n",
    "    correct_results = np.array((108.723235, 19.187791)).reshape(-1, 1)  # faster testing\n",
    "    fast_results = conley_cross_section(\"depth ~ mag\", quakes,\n",
    "                                        quakes_lat_long, cutoff)\n",
    "    assert_allclose(correct_results, fast_results)\n",
    "# test_quakes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quakes = feather.read_dataframe('tests/datasets/quakes.feather')\n",
    "quakes_lat = quakes['lat'].reshape(-1, 1)\n",
    "quakes_long = quakes['long'].reshape(-1, 1) - 180\n",
    "quakes_lat_long = np.hstack((quakes_lat, quakes_long))\n",
    "cutoff = 100\n",
    "\n",
    "balltree = BallTree(quakes_lat_long, metric = 'greatcircle')\n",
    "neighbors, distances = balltree.query_radius(quakes_lat_long, r = cutoff, return_distance = True)\n",
    "\n",
    "    \n",
    "y, X = dmatrices(data=quakes, formula_like='depth ~ mag')\n",
    "betahat, _, rank, _ = np.linalg.lstsq(X, y)\n",
    "if rank != X.shape[1]:\n",
    "    raise np.linalg.LinAlgError('X matrix is not full rank!')\n",
    "del rank\n",
    "residuals = (y - X @ betahat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conley_unfancy(y, X, lat_long, cutoff):\n",
    "    N = y.shape[0]\n",
    "    k = X.shape[1]\n",
    "    bread = np.linalg.inv(X.T @ X)  # 'bread' in the sandwich-estimator sense\n",
    "\n",
    "    # Run OLS to get residuals\n",
    "    betahat = bread @ X.T @ y  # '@' is matrix multiplication, equivalent to np.dot\n",
    "    residuals = y - X @ betahat\n",
    "    meat_matrix = np.zeros((k, k))\n",
    "    row_of_ones = np.ones((1, N))\n",
    "    column_of_ones = np.ones((k, 1))\n",
    "    # every_point_is_a_neighbor_of_every_other = True\n",
    "    for i in range(N):\n",
    "        dist = great_circle_one_to_many(lat_long, lat_long[i])\n",
    "\n",
    "        window = dist <= cutoff\n",
    "        # if not all(window):\n",
    "        #     every_point_is_a_neighbor_of_every_other = False\n",
    "        X_i = X[i, ].reshape(-1, 1)\n",
    "        residuals_i = residuals[i, ].reshape(-1, 1)\n",
    "\n",
    "        #         k x 1       1 x n        1 x 1\n",
    "        XeeXh = (((X_i @ row_of_ones * residuals_i) *\n",
    "                  (column_of_ones @ (residuals.T * window.T))) @ X)\n",
    "        #                 k x 1                1 x n            n x k\n",
    "        meat_matrix += XeeXh\n",
    "    meat_matrix = meat_matrix / N\n",
    "\n",
    "    sandwich = N * (bread.T @ meat_matrix @ bread)\n",
    "    se = np.sqrt(np.diag(sandwich)).reshape(-1, 1)\n",
    "    return se\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "\n",
    "def neighbors_to_sparse_nonuniform(neighbors, distances, kernel, cutoff):\n",
    "    nrow = neighbors.shape[0]\n",
    "    if distances is None:\n",
    "        raise ValueError('You must provide distances if using a non-uniform kernel')\n",
    "    if cutoff is None:\n",
    "        raise ValueError('You must provide a cutoff if using a non-uniform kernel')\n",
    "    if distances.shape[0] != nrow:\n",
    "        raise ValueError('neighbors and distances have different numbers of rows')\n",
    "        \n",
    "    neighbors_lil = lil_matrix((nrow, nrow), dtype=np.float_)\n",
    "    kernel_fn = get_kernel_fn(kernel)\n",
    "    for i, neighbor_list in enumerate(neighbors):\n",
    "        assert neighbor_list.shape == distances[i].shape\n",
    "        # fun fact: you have to apply the kernel function here; you can't do a sparse matrix \n",
    "        # of distances, since some distances (e.g. distance with self) are zero.\n",
    "        neighbors_lil[i, neighbor_list] = kernel_fn(distances[i], cutoff)\n",
    "    return neighbors_lil.tocsr()\n",
    "\n",
    "\n",
    "def neighbors_to_sparse_uniform(neighbors):\n",
    "    nrow = neighbors.shape[0]\n",
    "    neighbors_lil = lil_matrix((nrow, nrow), dtype=np.float_)\n",
    "    for i, neighbor_list in enumerate(neighbors):\n",
    "        neighbors_lil[i, neighbor_list] = 1\n",
    "    return neighbors_lil.tocsr()\n",
    "\n",
    "\n",
    "def neighbors_to_sparse(neighbors, kernel = 'uniform', distances = None, cutoff = None):\n",
    "    if kernel == 'uniform':\n",
    "        if cutoff is not None or distances is not None:\n",
    "            raise ValueError(\"this combination of parameters should never be necessary; it's a coding mistake\")\n",
    "        return neighbors_to_sparse_uniform(neighbors)\n",
    "    else:\n",
    "        return neighbors_to_sparse_nonuniform(neighbors, distances, kernel, cutoff)\n",
    "\n",
    "neighbors_sp = neighbors_to_sparse(neighbors)\n",
    "neighbors_sp[1,100]\n",
    "\n",
    "\n",
    "nrow = residuals.shape[0]\n",
    "# not smart enough to convert an (N, 1) array to a (N,) array, so manually reshape\n",
    "resid_diag_matrix = diags(residuals.reshape(-1), offsets=0, shape = (nrow, nrow))\n",
    "resid_x_neighbors = neighbors_sp * resid_diag_matrix\n",
    "\n",
    "# for i in range(residuals.shape[0]):\n",
    "#     resid_x_neighbors[i, :] *= residuals\n",
    "\n",
    "\n",
    "\n",
    "def test_mult_uniform(X, residuals, neighbors):\n",
    "    N = X.shape[0]\n",
    "    k = X.shape[1]\n",
    "    \n",
    "    \n",
    "    meat_matrix = np.zeros((k, k))\n",
    "    row_of_ones = np.ones((1, N))\n",
    "    column_of_ones = np.ones((k, 1))\n",
    "    neighbors_sp = neighbors_to_sparse(neighbors)\n",
    "    \n",
    "    neighbors_dense = neighbors_sp.toarray()\n",
    "    for i in range(N):\n",
    "        window = neighbors_dense[i, :]\n",
    "        X_i = X[i, ].reshape(-1, 1)\n",
    "        residuals_i = residuals[i, ].reshape(-1, 1)\n",
    "        \n",
    "        #         k x 1       1 x n        1 x 1\n",
    "        XeeXh = (((X_i @ row_of_ones * residuals_i) *\n",
    "                  (column_of_ones @ (residuals.T * window.T))) @ X)\n",
    "        #                 k x 1                1 x n            n x k\n",
    "        meat_matrix += XeeXh\n",
    "    correct = meat_matrix / N\n",
    "    \n",
    "    # I want element-wise multiplication of the residuals vector by the neighbors weights matrix.\n",
    "    # Sparse matrices don't have element-wise multiplication, but it's equivalent to cast \n",
    "    # the residuals as a sparse diagonal matrix, then do matrix multiplication.\n",
    "    # The diags function isn't smart enough to convert an (N, 1) array to a (N,) array, so manually reshape.\n",
    "    # Then, unlike numpy arrays, with sparse matrices, '*' means matrix multiplication, NOT element-wise.\n",
    "    resid_diag_matrix = diags(residuals.reshape(-1), offsets = 0, shape = (nrow, nrow))\n",
    "    # I want \n",
    "#     resid_cross = np.outer(residuals, residuals)\n",
    "    \n",
    "    resid_x_neighbors = resid_diag_matrix * neighbors_sp * resid_diag_matrix\n",
    "    \n",
    "    proposed = (X.T @ resid_x_neighbors @ X) / N\n",
    "    np.testing.assert_allclose(correct, proposed)\n",
    "#     bread = np.linalg.inv(X.T @ X)\n",
    "#     correct_sandwich = N * (bread.T @ correct @ bread)\n",
    "#     correct_se = np.sqrt(np.diag(correct_sandwich)).reshape(-1, 1)\n",
    "#     proposed_sandwich = N * (bread.T @ proposed @ bread)\n",
    "#     proposed_se = np.sqrt(np.diag(proposed_sandwich)).reshape(-1, 1)\n",
    "#     np.testing.assert_allclose(correct_se, proposed_se)\n",
    "    \n",
    "    \n",
    "%prun test_mult_uniform(X, residuals, neighbors)\n",
    "# test_mult(X, residuals, neighbors, distances, kernel = 'epanechnikov', cutoff = 100)\n",
    "\n",
    "#type(neighbors_sp)\n",
    "#print(resid_x_neighbors, neighbors_sp)\n",
    "# at_mult = \n",
    "# star_mult = X.T * resid_x_neighbors * X\n",
    "\n",
    "# print(at_mult.shape)\n",
    "# at_mult, star_mult)\n",
    "# residuals.reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 100  400  900]\n",
      " [   0 2000    0]\n",
      " [ 300 1200 2700]]\n",
      "True \n",
      " [[ 100  400  900]\n",
      " [   0 2000    0]\n",
      " [ 300 1200 2700]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array(([1,2,3], [0,5,0], [1,2,3]))\n",
    "y = np.array([10, 20, 30]).reshape(-1, 1)\n",
    "\n",
    "good = np.outer(y, y) * x\n",
    "print(good)\n",
    "test = (np.diagflat(y, k=0) @ x @ np.diagflat(y, k=0))\n",
    "\n",
    "print(np.allclose(good, test), '\\n', test)\n",
    "# print(x, '\\n\\n', np.diag(y), '\\n\\n',x @ np.diag(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_neighbors_to_sparse(neighbors, distances, cutoff):\n",
    "    from scipy.sparse import find\n",
    "    kernel = 'epanechnikov'  # just picked one for testing\n",
    "    neighbors_sparse_nodistance = neighbors_to_sparse(neighbors)\n",
    "    neighbors_sparse_withdistance = neighbors_to_sparse(neighbors, kernel, distances, cutoff)\n",
    "    kernel_fn = get_kernel_fn(kernel)\n",
    "    for i in range(neighbors.shape[0]):\n",
    "        neighbors_row_argsort = np.argsort(neighbors[i])  # get the indexes that will sort the row\n",
    "        neighbors_row_sorted = neighbors[i][neighbors_row_argsort]\n",
    "        \n",
    "        distance_row_sorted = kernel_fn(distances[i][neighbors_row_argsort], cutoff)\n",
    "        \n",
    "        # test that the neighbor indexes are the same\n",
    "        np.testing.assert_equal(find(neighbors_sparse_nodistance.getrow(i))[1], neighbors_row_sorted)\n",
    "        np.testing.assert_equal(find(neighbors_sparse_withdistance.getrow(i))[1], neighbors_row_sorted)\n",
    "        # test that the distance weight values are the same\n",
    "        np.testing.assert_equal(find(neighbors_sparse_withdistance.getrow(i))[2], distance_row_sorted)\n",
    "test_neighbors_to_sparse(neighbors, distances, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Error compiling Cython file:\n",
      "------------------------------------------------------------\n",
      "...\n",
      "    cdef int sparse_idx = 0\n",
      "    cdef int n_neighbors\n",
      "    for row_idx in range(nrow):\n",
      "        neighbors_row = neighbors[row_idx]\n",
      "        with nogil:\n",
      "            n_neighbors = len(neighbors_row)\n",
      "                            ^\n",
      "------------------------------------------------------------\n",
      "\n",
      "/home/karl/.cache/ipython/cython/_cython_magic_297db1f342d213226d04f7e1bd21e16a.pyx:32:29: Calling gil-requiring function not allowed without gil\n",
      "\n",
      "Error compiling Cython file:\n",
      "------------------------------------------------------------\n",
      "...\n",
      "    cdef int sparse_idx = 0\n",
      "    cdef int n_neighbors\n",
      "    for row_idx in range(nrow):\n",
      "        neighbors_row = neighbors[row_idx]\n",
      "        with nogil:\n",
      "            n_neighbors = len(neighbors_row)\n",
      "                                          ^\n",
      "------------------------------------------------------------\n",
      "\n",
      "/home/karl/.cache/ipython/cython/_cython_magic_297db1f342d213226d04f7e1bd21e16a.pyx:32:43: Converting to Python object not allowed without gil\n"
     ]
    }
   ],
   "source": [
    "%%cython --annotate\n",
    "import numpy as np\n",
    "cimport numpy as cnp\n",
    "from typedefs cimport DTYPE_t, ITYPE_t\n",
    "from typedefs import DTYPE, ITYPE\n",
    "import cython\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "\n",
    "@cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "@cython.wraparound(False)  # turn off negative indexing\n",
    "cpdef object neighbors_to_sparse_uniform_cython(object[:] neighbors):\n",
    "    cdef int i_neighbor\n",
    "    cdef int nrow = len(neighbors)\n",
    "    cdef int nnz = 0  # number of non-zeros\n",
    "    for i_neighbor in range(nrow):\n",
    "        nnz += len(neighbors[i_neighbor])\n",
    "    \n",
    "    cdef ITYPE_t[:] rows = np.empty(nnz, dtype=ITYPE)\n",
    "    cdef ITYPE_t[:] cols = np.empty(nnz, dtype=ITYPE)\n",
    "    # for values, use dtype (i.e., float64) because even though it's \n",
    "    # always going to be 1, I want the same type for nonuniform\n",
    "    cdef DTYPE_t[:] values = np.empty(nnz, dtype=DTYPE)  \n",
    "    \n",
    "    cdef ITYPE_t[:] neighbors_row\n",
    "    cdef int row_idx, neighbor_id\n",
    "    cdef int sparse_idx = 0\n",
    "    cdef int n_neighbors\n",
    "    for row_idx in range(nrow):\n",
    "        neighbors_row = neighbors[row_idx]\n",
    "        n_neighbors = len(neighbors_row)\n",
    "        with nogil:\n",
    "            for neighbor_id in range(n_neighbors):\n",
    "                rows[sparse_idx] = row_idx\n",
    "                cols[sparse_idx] = neighbors_row[neighbor_id]\n",
    "                values[sparse_idx] = 1\n",
    "                sparse_idx += 1\n",
    "    # Finally, we construct a regular SciPy sparse matrix:\n",
    "    return coo_matrix((values, (rows, cols)), shape=(nrow, nrow)).tocsr()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 5.26 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit neighbors_to_sparse_uniform_cython(neighbors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 97.4 ms per loop\n",
      "100 loops, best of 3: 17.8 ms per loop\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def neighbors_to_sparse_uniform(neighbors):\n",
    "    nrow = neighbors.shape[0]\n",
    "    neighbors_lil = lil_matrix((nrow, nrow), dtype=np.float_)\n",
    "    for i, neighbor_list in enumerate(neighbors):\n",
    "        neighbors_lil[i, neighbor_list] = 1\n",
    "    return neighbors_lil.tocsr()\n",
    "%timeit neighbors_to_sparse_uniform(neighbors)\n",
    "\n",
    "\n",
    "def neighbors_to_sparse_uniform2(neighbors):\n",
    "    \n",
    "    nrow = len(neighbors)\n",
    "    nnz = 0  # number of non-zeros\n",
    "    for i_neighbor in range(nrow):\n",
    "        nnz += len(neighbors[i_neighbor])\n",
    "    \n",
    "    rows   = np.empty(nnz, dtype=ITYPE)\n",
    "    cols   = np.empty(nnz, dtype=ITYPE)\n",
    "    values = np.empty(nnz, dtype=DTYPE)  \n",
    "    sparse_idx = 0\n",
    "    for row_idx in range(nrow):\n",
    "        neighbors_row = neighbors[row_idx]\n",
    "        for neighbor_id in neighbors_row:\n",
    "            rows[sparse_idx] = row_idx\n",
    "            cols[sparse_idx] = neighbor_id\n",
    "            values[sparse_idx] = 1\n",
    "            sparse_idx += 1\n",
    "    assert sparse_idx == nnz\n",
    "\n",
    "    # Finally, we construct a regular SciPy sparse matrix:\n",
    "    return coo_matrix((values, (rows, cols)), shape=(nrow, nrow)).tocsr()\n",
    "\n",
    "%timeit neighbors_to_sparse_uniform2(neighbors)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
